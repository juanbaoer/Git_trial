{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8013df17-94bb-4aac-877b-04246ece92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def _standardize(kernel):\n",
    "    \"\"\"\n",
    "    Makes sure that Var(W) = 1 and E[W] = 0\n",
    "    \"\"\"\n",
    "    eps = 1e-6\n",
    "\n",
    "    if len(kernel.shape) == 3:\n",
    "        axis = [0, 1]  # last dimension is output dimension\n",
    "    else:\n",
    "        axis = 1\n",
    "\n",
    "    var, mean = torch.var_mean(kernel, dim=axis, unbiased=True, keepdim=True)\n",
    "    kernel = (kernel - mean) / (var + eps) ** 0.5\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def he_orthogonal_init(tensor):\n",
    "    \"\"\"\n",
    "    Generate a weight matrix with variance according to He initialization.\n",
    "    Based on a random (semi-)orthogonal matrix neural networks\n",
    "    are expected to learn better when features are decorrelated\n",
    "    (stated by eg. \"Reducing overfitting in deep networks by decorrelating representations\",\n",
    "    \"Dropout: a simple way to prevent neural networks from overfitting\",\n",
    "    \"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks\")\n",
    "    \"\"\"\n",
    "    tensor = torch.nn.init.orthogonal_(tensor)\n",
    "\n",
    "    if len(tensor.shape) == 3:\n",
    "        fan_in = tensor.shape[:-1].numel()\n",
    "    else:\n",
    "        fan_in = tensor.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tensor.data = _standardize(tensor.data)\n",
    "        tensor.data *= (1 / fan_in) ** 0.5\n",
    "\n",
    "    return tensor\n",
    "\n",
    "class Dense(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Combines dense layer and scaling for swish activation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        units: int\n",
    "            Output embedding size.\n",
    "        activation: str\n",
    "            Name of the activation function to use.\n",
    "        bias: bool\n",
    "            True if use bias.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_features, out_features, bias=False, activation=None, name=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.reset_parameters()\n",
    "        self.weight = self.linear.weight\n",
    "        self.bias = self.linear.bias\n",
    "\n",
    "        if isinstance(activation, str):\n",
    "            activation = activation.lower()\n",
    "        if activation in [\"swish\", \"silu\"]:\n",
    "            self._activation = ScaledSiLU()\n",
    "        elif activation is None:\n",
    "            self._activation = torch.nn.Identity()\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"Activation function not implemented for GemNet (yet).\"\n",
    "            )\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        he_orthogonal_init(self.linear.weight)\n",
    "        if self.linear.bias is not None:\n",
    "            self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self._activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScaledSiLU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scale_factor = 1 / 0.6\n",
    "        self._activation = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(x) * self.scale_factor\n",
    "\n",
    "\n",
    "class ResidualLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with output scaled by 1/sqrt(2).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        units: int\n",
    "            Output embedding size.\n",
    "        nLayers: int\n",
    "            Number of dense layers.\n",
    "        activation: str\n",
    "            Name of the activation function to use.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, units: int, nLayers: int = 2, activation=None, name=None):\n",
    "        super().__init__()\n",
    "        self.dense_mlp = torch.nn.Sequential(\n",
    "            *[\n",
    "                Dense(units, units, activation=activation, bias=False)\n",
    "                for i in range(nLayers)\n",
    "            ]\n",
    "        )\n",
    "        self.inv_sqrt_2 = 1 / (2.0 ** 0.5)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.dense_mlp(inputs)\n",
    "        x = inputs + x\n",
    "        x = x * self.inv_sqrt_2\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdad4d10-77bc-4750-944b-72ba615154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn import GraphNorm, InstanceNorm\n",
    "\n",
    "# from . import ResidualLayer, Dense, he_orthogonal_init\n",
    "\n",
    "class CoorsNorm(nn.Module):\n",
    "    def __init__(self, eps = 1e-8, scale_init = 1.):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        scale = torch.zeros(1).fill_(scale_init)\n",
    "        self.scale = nn.Parameter(scale)\n",
    "\n",
    "    def forward(self, coors):\n",
    "        norm = coors.norm(dim = -1, keepdim = True)\n",
    "        normed_coors = coors / norm.clamp(min = self.eps)\n",
    "        return normed_coors * self.scale\n",
    "\n",
    "class Envelope(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Envelope function that ensures a smooth cutoff.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        p: int\n",
    "            Exponent of the envelope function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p, name=\"envelope\"):\n",
    "        super().__init__()\n",
    "        assert p > 0\n",
    "        self.p = p\n",
    "        self.a = -(self.p + 1) * (self.p + 2) / 2\n",
    "        self.b = self.p * (self.p + 2)\n",
    "        self.c = -self.p * (self.p + 1) / 2\n",
    "\n",
    "    def forward(self, d_scaled):\n",
    "        env_val = (\n",
    "            1\n",
    "            + self.a * d_scaled ** self.p\n",
    "            + self.b * d_scaled ** (self.p + 1)\n",
    "            + self.c * d_scaled ** (self.p + 2)\n",
    "        )\n",
    "        return torch.where(d_scaled < 1, env_val, torch.zeros_like(d_scaled))\n",
    "\n",
    "def calculate_neighbor_angles(R_ac, R_ab):\n",
    "        \"\"\"Calculate angles between atoms c <- a -> b.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            R_ac: Tensor, shape = (N,dim)\n",
    "                Vector from atom a to c.\n",
    "            R_ab: Tensor, shape = (N,dim)\n",
    "                Vector from atom a to b.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            angle_cab: Tensor, shape = (N, 2)\n",
    "                [sin, cos] tensor between atoms c <- a -> b.\n",
    "            angle_cab: Tensor, shape = (N, 1)\n",
    "                theta belong to [0, pi] tensor between atoms c <- a -> b.\n",
    "        \"\"\"\n",
    "        # Normalize vectors\n",
    "        R_ac = R_ac / R_ac.norm(dim = -1, keepdim = True).clamp(min = 1e-8)\n",
    "        R_ab = R_ab / R_ab.norm(dim = -1, keepdim = True).clamp(min = 1e-8)\n",
    "        \n",
    "        # cos(alpha) = (u * v) / (|u|*|v|)\n",
    "        x = torch.sum(- R_ac * R_ab, dim=1, keepdim=True)  # shape = (N,1)\n",
    "        \n",
    "        # Check vector dimension to calculate sin(alpha)\n",
    "        dim = R_ac.size(-1)\n",
    "        assert(dim == 2 or dim == 3), \"Only 2D and 3D angles are supported.\"\n",
    "        if dim == 3:\n",
    "            # 3D: sin(alpha) = |u × v| / (|u|*|v|) using cross product\n",
    "            y = torch.cross(R_ac, R_ab).norm(dim=-1, keepdim=True)  # shape = (N,1)\n",
    "        elif dim == 2:\n",
    "            # 2D: sin(alpha) = (u.x*v.y - u.y*v.x) / (|u|*|v|)\n",
    "            y = torch.abs(- R_ac[:, 0:1] * R_ab[:, 1:2] + R_ac[:, 1:2] * R_ab[:, 0:1])  # shape = (N,1)\n",
    "        \n",
    "        # Avoid numerical issues for gradient calculation\n",
    "        y = torch.max(y, torch.tensor(1e-9, device=y.device))\n",
    "        \n",
    "        # Return [sin, cos] tensors\n",
    "        # angle = torch.cat([y, x], dim=-1)  # shape = (N,2)\n",
    "        angle = torch.atan2(y, x)\n",
    "        # angle = x\n",
    "        return angle\n",
    "\n",
    "# Moved build_graph to module level for cleaner code structure\n",
    "def build_graph(globs, coors, feats = None, edges = None, cutoff = math.inf, mask = None):\n",
    "    \"\"\"\n",
    "    Build the graph structure from coordinates\n",
    "    \n",
    "    Args:\n",
    "        globs: global attributes [b, g]\n",
    "        coors: coordinate [b, n, d]\n",
    "        feats: optional node features [b, n, f]\n",
    "        edges: optional edge features [b, n, n, e]\n",
    "        cutoff_distance: maximum distance for edge creation\n",
    "        mask: optional mask [b, n, n]\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing all graph information including triplet data\n",
    "    \"\"\"\n",
    "    b, n, d = coors.shape\n",
    "    device = coors.device\n",
    "    cutoff = (2 * math.pi) ** 2 if cutoff > (2 * math.pi) ** 2 else cutoff\n",
    "    \n",
    "    # Compute relative coordinates for all pairs\n",
    "    rel_coors = - coors[:,:,None,:] + coors[:,None,:,:]  #  - [b, i, 1, d] + [b, 1, j, d] = [b, i, j, d] vec from i to j\n",
    "    \n",
    "    # Apply periodic boundary conditions\n",
    "    rel_coors = rel_coors - 2 * math.pi * torch.round(rel_coors / (2 * math.pi))\n",
    "    \n",
    "    # Compute chord distance\n",
    "    # rel_dist = (2 - 2 * torch.cos(rel_coors)).sum(dim=-1, keepdim=True)  # [b, n, n, 1]\n",
    "    # Compute geodesic distance\n",
    "    rel_dists = (rel_coors ** 2).sum(dim = -1, keepdim = True)  # [b, i, j, 1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Create distance-based cutoff mask\n",
    "        dist_mask = (rel_dists <= cutoff) & (rel_dists > 0)  # [b, i, j, 1]\n",
    "        deg = dist_mask.sum(dim=-2).flatten()  # [b*i] - number of valid edges per node\n",
    "        deg_max = deg.max()  \n",
    "        deg_cum = deg.cumsum(dim=0) - deg  # [b*i] - cumulative sum of degrees\n",
    "        \n",
    "        # Combine with provided mask if it exists\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(-1) & dist_mask\n",
    "        else:\n",
    "            mask = dist_mask\n",
    "        del dist_mask\n",
    "            \n",
    "        # Vectorized batch processing using PyG's batch support\n",
    "        mask_flat = mask.flatten()  # [b*i*j]\n",
    "        \n",
    "        # Use meshgrid to efficiently create source and target indices\n",
    "        row, col = torch.meshgrid(\n",
    "            torch.arange(n, device=device),\n",
    "            torch.arange(n, device=device),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        source_indices = row.flatten()  # [n*n]\n",
    "        target_indices = col.flatten()  # [n*n]\n",
    "        \n",
    "        # Create batch offsets more efficiently\n",
    "        batch_index = torch.arange(b, device=device).repeat_interleave(n*n)  # [b*n*n]\n",
    "        batch_offsets = batch_index * n  # [b*n*n]\n",
    "        \n",
    "        # Apply offsets directly\n",
    "        batch_source = source_indices.repeat(b) + batch_offsets  # [b*n*n]\n",
    "        batch_target = target_indices.repeat(b) + batch_offsets  # [b*n*n]\n",
    "        \n",
    "        # Filter edges based on the mask\n",
    "        valid_edges = mask_flat.bool()\n",
    "        batch_index = batch_index[valid_edges]  # [num_edges]\n",
    "        edge_index = torch.stack([\n",
    "            batch_source[valid_edges],\n",
    "            batch_target[valid_edges]\n",
    "        ])  # [2, num_edges]\n",
    "        # num_edges = edge_index.shape[1]  # Number of edges\n",
    "\n",
    "        # pivot_node_index = edge_index[1]  # [num_edges] \n",
    "        # pivot_edge_num = deg[pivot_node_index]  # [num_edges]\n",
    "        # num_triplets = pivot_edge_num.sum()  # Total number of triplets\n",
    "        \n",
    "        # # Create triplet indices\n",
    "        # # For each edge j->k, find all edges i->j to create triplets (i->j, j->k)\n",
    "        # # Repeat each edge index according to number of incoming edges to its target node\n",
    "        # triplet_left_index = torch.repeat_interleave(torch.arange(num_edges, device=device), pivot_edge_num)  # [num_triplets]\n",
    "        \n",
    "        # # Calculate base offset for the starting index of each node's edge list\n",
    "        # triplet_right_base = torch.repeat_interleave(deg_cum[pivot_node_index], pivot_edge_num)  # [num_triplets]\n",
    "        \n",
    "        # # Calculate relative index within each node's edge list\n",
    "        # # Create sequential indices and reset counter at the start of each new node group\n",
    "        # group_offsets = torch.repeat_interleave(torch.cumsum(pivot_edge_num, dim=0) - pivot_edge_num, pivot_edge_num)\n",
    "        # triplet_right_kidx = torch.arange(num_triplets, device=device) - group_offsets  # [num_triplets]\n",
    "        \n",
    "        # # Combine base and relative indices to get final right edge indices\n",
    "        # triplet_right_index = triplet_right_base + triplet_right_kidx  # [num_triplets]\n",
    "\n",
    "        # # Filter out self-loops in triplets (where source of left edge equals target of right edge)\n",
    "        # left_src_index = edge_index[0][triplet_left_index]  # Source nodes of left edges\n",
    "        # right_tgt_index = edge_index[1][triplet_right_index]  # Target nodes of right edges\n",
    "        # triplet_mask = (left_src_index != right_tgt_index)  # Exclude self-connections\n",
    "        \n",
    "        # # Final triplet indices: pairs of (left_edge_idx, right_edge_idx) forming valid triplets\n",
    "        # triplet_index = torch.stack([\n",
    "        #     triplet_left_index[triplet_mask],\n",
    "        #     triplet_right_index[triplet_mask]\n",
    "        # ])\n",
    "        # num_triplets = triplet_index.shape[1]  # Number of triplets\n",
    "\n",
    "    # Reshape coordinates and features based on the mask\n",
    "    coors = coors.flatten(end_dim=-2)  # [b*n, d]\n",
    "    if feats is not None:\n",
    "        feats = feats.flatten(end_dim=-2)  # [b*n, f]\n",
    "\n",
    "    # Reshape coordinates and distances based on the mask\n",
    "    globs = globs[batch_index]  # [num_edges, g]\n",
    "    rel_coors = rel_coors.reshape(-1, d)[valid_edges]  # [num_edges, d]\n",
    "    rel_dists = rel_dists.reshape(-1, 1)[valid_edges]  # [num_edges, 1]\n",
    "    if edges is not None:\n",
    "        edges = edges.flatten(end_dim=-2)[valid_edges]  # [num_edges, e]\n",
    "    \n",
    "    # triplet_angles = calculate_neighbor_angles(\n",
    "    #     rel_coors[triplet_index[0]],  # [num_triplets, d]\n",
    "    #     rel_coors[triplet_index[1]]   # [num_triplets, d]\n",
    "    # )  # [num_triplets, 2]\n",
    "\n",
    "    # Return all the necessary components for graph operations\n",
    "    return {\n",
    "        'edge_index': edge_index,\n",
    "        'globs': globs,\n",
    "        'coors': coors,\n",
    "        # 'triplet_index': triplet_index,\n",
    "        # 'triplet_angles': triplet_angles,\n",
    "        'feats': feats,\n",
    "        'edges': edges,\n",
    "        'rel_coors': rel_coors,\n",
    "        'rel_dists': rel_dists,\n",
    "        'b': b,\n",
    "        'n': n,\n",
    "        'd': d,\n",
    "        # 'num_edges': num_edges,\n",
    "        # 'num_triplets': num_triplets,\n",
    "    }\n",
    "\n",
    "# class Triplet_MessagePassing(MessagePassing):\n",
    "#     def __init__(self, edge_input_dim: int, edge_out_dim: int, triplet_hidden_dim: int):\n",
    "#         super().__init__(aggr='add')  # Use \"add\" aggregation\n",
    "\n",
    "#         # triplet_input_dim = 2 * edge_input_dim + 2  # Include angles\n",
    "#         # triplet_input_dim = edge_input_dim + 2  # Include angles\n",
    "#         triplet_input_dim = edge_input_dim + 1  # Include angles\n",
    "\n",
    "#         self.triplet_mlp = nn.Sequential(\n",
    "#             Dense(triplet_input_dim, triplet_hidden_dim, activation='silu'),\n",
    "#             nn.SiLU(),\n",
    "#             ResidualLayer(triplet_hidden_dim, 2, activation='silu', name=None)\n",
    "#         )\n",
    "\n",
    "#         self.triplet_gate = nn.Sequential(\n",
    "#             Dense(triplet_hidden_dim, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#         # Add bilinear layer to combine edge attributes with triplet messages\n",
    "#         self.edge_update_bilinear = nn.Bilinear(edge_input_dim, triplet_hidden_dim, edge_out_dim, bias=False)\n",
    "#         he_orthogonal_init(self.edge_update_bilinear.weight)\n",
    "\n",
    "\n",
    "#     def forward(self, edge_message, triplet_index, triplet_angles, **kwargs):\n",
    "\n",
    "#         # Run message passing - pass edge_attr to update() via the propagate call\n",
    "#         edge_message_updated = self.propagate(\n",
    "#             triplet_index,\n",
    "#             edge_message=edge_message,\n",
    "#             triplet_angles=triplet_angles,\n",
    "#         )\n",
    "        \n",
    "#         # Return updated edge attributes\n",
    "#         return edge_message_updated\n",
    "\n",
    "#     def message(self, edge_message_i, edge_message_j, triplet_angles):\n",
    "\n",
    "#         # triplet_attr = torch.cat([edge_message_i, edge_message_i, triplet_angles], dim=-1)\n",
    "#         triplet_attr = torch.cat([edge_message_j, triplet_angles], dim=-1)  # [num_triplet, triplet_input_dim]\n",
    "\n",
    "#         # Process edge attributes\n",
    "#         m_ijk = self.triplet_mlp(triplet_attr)\n",
    "#         m_ijk = m_ijk * self.triplet_gate(m_ijk)  # Apply gating\n",
    "        \n",
    "#         return m_ijk  # [num_triplet, triplet_hidden_dim]\n",
    "\n",
    "#     def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
    "#         # Use the default aggregation (sum)\n",
    "#         return super().aggregate(inputs, index, ptr, dim_size)\n",
    "\n",
    "#     def update(self, aggr_out, edge_message):\n",
    "#         # Apply bilinear layer to combine original edge attributes with triplet messages\n",
    "#         edge_message_updated = self.edge_update_bilinear(edge_message, aggr_out)\n",
    "#         return edge_message_updated\n",
    "\n",
    "\n",
    "# Based on E(n)-Equivariant Graph Neural Networks in torus space\n",
    "class Coordinate_EGNN(MessagePassing):\n",
    "    def __init__(self, glob_dim: int, feat_dim: int = 0, edge_dim: int = 0, hidden_dim: int = 64,\n",
    "                 cutoff_distance: float = math.inf, \n",
    "                 norm_coors_scale_init: float = 1., \n",
    "                 envelope_exponent: int = 5):\n",
    "        super().__init__(aggr=\"add\")  # Use \"add\" aggregation\n",
    "        \n",
    "        self.cutoff_distance = (2 * math.pi) ** 2 if cutoff_distance > (2 * math.pi) ** 2 else cutoff_distance\n",
    "        # Update edge_input_dim to include features from both source and target nodes\n",
    "        edge_input_dim = glob_dim + 1 + (2 * feat_dim) + edge_dim\n",
    "        \n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            Dense(edge_input_dim, hidden_dim, activation='silu'),\n",
    "            nn.SiLU(),\n",
    "            ResidualLayer(hidden_dim, 2, activation='silu', name=None)\n",
    "        )\n",
    "\n",
    "        self.edge_gate = nn.Sequential(\n",
    "            Dense(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.coors_norm = CoorsNorm(scale_init = norm_coors_scale_init)\n",
    "\n",
    "        self.vec_mlp = nn.Sequential(\n",
    "            ResidualLayer(hidden_dim, 2, activation='silu', name=None),\n",
    "            nn.SiLU(),\n",
    "            Dense(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.envelope = Envelope(envelope_exponent)\n",
    "\n",
    "        self.inv_sqrt_2 = 1 / (2.0 ** 0.5)\n",
    "\n",
    "    def forward(self, graph_dict):\n",
    "        '''\n",
    "        globs: global attributes B*D'\n",
    "        coors: coordinate (vec) attributes B*N*D\n",
    "        '''\n",
    "\n",
    "        # Extract parameters from the provided graph_dict\n",
    "        b, n, d = graph_dict['b'], graph_dict['n'], graph_dict['d']\n",
    "        edge_index = graph_dict['edge_index']\n",
    "        globs = graph_dict['globs']\n",
    "        coors = graph_dict['coors']\n",
    "        feats = graph_dict['feats']\n",
    "        edges = graph_dict['edges']\n",
    "        rel_coors = graph_dict['rel_coors']\n",
    "        rel_dists = graph_dict['rel_dists']\n",
    "        # num_edges = graph_dict['num_edges']\n",
    "        # num_triplets = graph_dict['num_triplets']\n",
    "        \n",
    "        # Create edge attributes - start with global attributes and distances\n",
    "        edge_attr = torch.cat([globs, rel_dists], dim=-1)\n",
    "        dists_env = self.envelope(rel_dists / self.cutoff_distance)\n",
    "        \n",
    "        # Conditionally add edge features if they exist\n",
    "        if edges is not None:\n",
    "            edge_attr = torch.cat([edge_attr, edges], dim=-1)\n",
    "        \n",
    "        # Run message passing\n",
    "        coor_update = self.propagate(\n",
    "            edge_index,\n",
    "            size=(b * n, b * n),  # Size of the graph\n",
    "            feats=feats,\n",
    "            rel_coors=rel_coors,\n",
    "            dists_env = dists_env,\n",
    "            edge_attr=edge_attr\n",
    "        )\n",
    "        \n",
    "        coors = coors + coor_update\n",
    "\n",
    "        rel_coors = - coors[edge_index[0]] + coors[edge_index[1]]  # [num_edges, d] vec from i to j\n",
    "        rel_coors = rel_coors - 2 * math.pi * torch.round(rel_coors / (2 * math.pi))\n",
    "\n",
    "        rel_dists = (rel_coors ** 2).sum(dim = -1, keepdim = True)  # [num_edges, 1]\n",
    "\n",
    "        graph_dict['coors'] = coors\n",
    "        graph_dict['rel_coors'] = rel_coors\n",
    "        graph_dict['rel_dists'] = rel_dists\n",
    "        \n",
    "        return coors\n",
    "    \n",
    "    def message(self, feats_i, feats_j, rel_coors, dists_env, edge_attr):\n",
    "        if feats_i is not None and feats_j is not None:\n",
    "            # Concatenate features from both source and target nodes\n",
    "            edge_attr = torch.cat([edge_attr, feats_i, feats_j], dim=-1)\n",
    "\n",
    "        # Process edge attributes\n",
    "        m_ij = self.edge_mlp(edge_attr)\n",
    "        m_ij = m_ij * self.edge_gate(m_ij)  # Apply gating\n",
    "        \n",
    "        # Compute vector messages\n",
    "        mij_hat = self.vec_mlp(m_ij)  # [num_edges, 1]\n",
    "\n",
    "        # Normalize relative coordinates\n",
    "        rel_coors_norm = self.coors_norm(rel_coors)\n",
    "        \n",
    "        # Scale relative coordinates\n",
    "        return mij_hat * rel_coors_norm * dists_env  # [num_edges, d]\n",
    "    \n",
    "    def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
    "        # Use the default aggregation (sum)\n",
    "        return super().aggregate(inputs, index, ptr, dim_size)\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        # No additional processing needed after aggregation\n",
    "        return aggr_out\n",
    "\n",
    "# Based on E(n)-Equivariant Graph Neural Networks in torus space\n",
    "# class Coordinate_Triplet_EGNN(MessagePassing):\n",
    "#     def __init__(self, glob_dim: int, feat_dim: int = 0, edge_dim: int = 0, hidden_dim: int = 64,\n",
    "#                  cutoff_distance: float = math.inf, \n",
    "#                  norm_coors_scale_init: float = 1., \n",
    "#                  envelope_exponent: int = 5):\n",
    "#         super().__init__(aggr=\"add\")  # Use \"add\" aggregation\n",
    "        \n",
    "#         self.cutoff_distance = (2 * math.pi) ** 2 if cutoff_distance > (2 * math.pi) ** 2 else cutoff_distance\n",
    "#         # Update edge_input_dim to include features from both source and target nodes\n",
    "#         edge_input_dim = glob_dim + 1 + (2 * feat_dim) + edge_dim\n",
    "        \n",
    "#         self.edge_mlp = nn.Sequential(\n",
    "#             Dense(edge_input_dim, hidden_dim, activation='silu'),\n",
    "#             nn.SiLU(),\n",
    "#             ResidualLayer(hidden_dim, 2, activation='silu', name=None)\n",
    "#         )\n",
    "\n",
    "#         self.edge_gate = nn.Sequential(\n",
    "#             Dense(hidden_dim, 1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#         self.triplet_interaction = Triplet_MessagePassing(\n",
    "#             edge_input_dim=hidden_dim,\n",
    "#             edge_out_dim=hidden_dim // 2,\n",
    "#             triplet_hidden_dim=hidden_dim\n",
    "#         )\n",
    "\n",
    "#         self.coors_norm = CoorsNorm(scale_init = norm_coors_scale_init)\n",
    "\n",
    "#         self.vec_alpha_mlp = nn.Sequential(\n",
    "#             ResidualLayer(hidden_dim, 2, activation='silu', name=None),\n",
    "#             nn.SiLU(),\n",
    "#             Dense(hidden_dim, 1),\n",
    "#         )\n",
    "\n",
    "#         self.vec_beta_mlp = nn.Sequential(\n",
    "#             ResidualLayer(hidden_dim // 2, 2, activation='silu', name=None),\n",
    "#             nn.SiLU(),\n",
    "#             Dense(hidden_dim // 2, 1),\n",
    "#         )\n",
    "\n",
    "#         self.envelope = Envelope(envelope_exponent)\n",
    "\n",
    "#         self.inv_sqrt_2 = 1 / (2.0 ** 0.5)\n",
    "\n",
    "#     def forward(self, graph_dict):\n",
    "#         '''\n",
    "#         globs: global attributes B*D'\n",
    "#         coors: coordinate (vec) attributes B*N*D\n",
    "#         '''\n",
    "\n",
    "#         # Extract parameters from the provided graph_dict\n",
    "#         b, n, d = graph_dict['b'], graph_dict['n'], graph_dict['d']\n",
    "#         edge_index = graph_dict['edge_index']\n",
    "#         triplet_index = graph_dict['triplet_index']\n",
    "#         triplet_angles = graph_dict['triplet_angles']\n",
    "#         globs = graph_dict['globs']\n",
    "#         coors = graph_dict['coors']\n",
    "#         feats = graph_dict['feats']\n",
    "#         edges = graph_dict['edges']\n",
    "#         rel_coors = graph_dict['rel_coors']\n",
    "#         rel_dists = graph_dict['rel_dists']\n",
    "#         num_edges = graph_dict['num_edges']\n",
    "#         num_triplets = graph_dict['num_triplets']\n",
    "        \n",
    "#         # Create edge attributes - start with global attributes and distances\n",
    "#         edge_attr = torch.cat([globs, rel_dists], dim=-1)\n",
    "#         dists_env = self.envelope(rel_dists / self.cutoff_distance)\n",
    "        \n",
    "#         # Conditionally add edge features if they exist\n",
    "#         if edges is not None:\n",
    "#             edge_attr = torch.cat([edge_attr, edges], dim=-1)\n",
    "        \n",
    "#         # Run message passing\n",
    "#         coor_update = self.propagate(\n",
    "#             edge_index,\n",
    "#             size=(b * n, b * n),  # Size of the graph\n",
    "#             feats=feats,\n",
    "#             rel_coors=rel_coors,\n",
    "#             dists_env = dists_env,\n",
    "#             edge_attr=edge_attr,\n",
    "#             triplet_index = triplet_index,\n",
    "#             triplet_angles = triplet_angles,\n",
    "#         )\n",
    "        \n",
    "#         coors = coors + coor_update\n",
    "\n",
    "#         rel_coors = - coors[edge_index[0]] + coors[edge_index[1]]  # [num_edges, d] vec from i to j\n",
    "#         rel_coors = rel_coors - 2 * math.pi * torch.round(rel_coors / (2 * math.pi))\n",
    "\n",
    "#         rel_dists = (rel_coors ** 2).sum(dim = -1, keepdim = True)  # [num_edges, 1]\n",
    "\n",
    "#         graph_dict['coors'] = coors\n",
    "#         graph_dict['rel_coors'] = rel_coors\n",
    "#         graph_dict['rel_dists'] = rel_dists\n",
    "        \n",
    "#         return coors\n",
    "    \n",
    "#     def message(self, feats_i, feats_j, rel_coors, dists_env, edge_attr, triplet_index, triplet_angles):\n",
    "#         if feats_i is not None and feats_j is not None:\n",
    "#             # Concatenate features from both source and target nodes\n",
    "#             edge_attr = torch.cat([edge_attr, feats_i, feats_j], dim=-1)\n",
    "\n",
    "#         # Process edge attributes\n",
    "#         m_ij = self.edge_mlp(edge_attr)\n",
    "#         m_ij = m_ij * self.edge_gate(m_ij)  # Apply gating\n",
    "\n",
    "#         m_ij_triplet = self.triplet_interaction(m_ij, triplet_index, triplet_angles)\n",
    "        \n",
    "#         # Compute vector messages\n",
    "#         mij_alpha = self.vec_alpha_mlp(m_ij)  # [num_edges, 1]\n",
    "#         mij_beta = self.vec_beta_mlp(m_ij_triplet)  # [num_edges, 1]\n",
    "\n",
    "#         # Normalize relative coordinates\n",
    "#         rel_coors_norm = self.coors_norm(rel_coors)\n",
    "        \n",
    "#         # Scale relative coordinates\n",
    "#         return (mij_alpha + mij_beta) * rel_coors_norm * dists_env  # [num_edges, d]\n",
    "    \n",
    "#     def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
    "#         # Use the default aggregation (sum)\n",
    "#         return super().aggregate(inputs, index, ptr, dim_size)\n",
    "    \n",
    "#     def update(self, aggr_out):\n",
    "#         # No additional processing needed after aggregation\n",
    "#         return aggr_out\n",
    "\n",
    "# Multi-layer version of CoordinateEGNN with optimized graph construction\n",
    "class PINN2D(nn.Module):\n",
    "    def __init__(self, glob_dim: int, feat_dim: int = 0, edge_dim: int = 0, hidden_dim: int = 64, \n",
    "                 norm_coors_scale_init: float = 1.0, cutoff_distance: float = math.inf, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        self.cutoff_distance = cutoff_distance\n",
    "        \n",
    "        # Create a ModuleList to hold multiple EGNN layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            Coordinate_EGNN(\n",
    "            # Coordinate_Triplet_EGNN(\n",
    "                glob_dim=glob_dim, \n",
    "                feat_dim=feat_dim, \n",
    "                edge_dim=edge_dim, \n",
    "                hidden_dim=hidden_dim, \n",
    "                norm_coors_scale_init=norm_coors_scale_init, \n",
    "                cutoff_distance=cutoff_distance,\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, globs, coors, shape, feats=None, edges=None, mask=None):\n",
    "        \"\"\"\n",
    "        Apply multiple EGNN layers sequentially with a single graph construction\n",
    "        \n",
    "        Args:\n",
    "            globs: global attributes (batch_size, D')\n",
    "            coors: flattened coordinate attributes (total_size, d)\n",
    "            shape: tuple of (batch_size, n_particles, dim) to reshape coordinates\n",
    "            feats: node features (optional)\n",
    "            edges: edge features (optional)\n",
    "            mask: attention mask (optional)\n",
    "        \"\"\"\n",
    "        # Extract shape information\n",
    "        b, n, d = shape\n",
    "        \n",
    "        # Reshape flattened coordinates to (b, n, d) for graph building\n",
    "        coors = coors.reshape(b, n, d)\n",
    "        feats = feats.reshape(b, n, -1) if feats is not None else None\n",
    "        edges = edges.reshape(b, n, n, -1) if edges is not None else None\n",
    "\n",
    "        # Build graph structure once using the standalone function\n",
    "        graph_dict = build_graph(globs, coors, feats, edges, self.cutoff_distance, mask)\n",
    "\n",
    "        coors_residual = graph_dict['coors']\n",
    "        \n",
    "        # Apply each layer sequentially using the same graph structure\n",
    "        for layer in self.layers:\n",
    "            coors = layer(graph_dict)\n",
    "        \n",
    "        graph_dict['coors'] -= coors_residual\n",
    "        \n",
    "        return graph_dict['coors'].reshape(b, n*d)\n",
    "\n",
    "# class Coordinate_Volume_Network(nn.Module):\n",
    "#     def __init__(self, glob_dim: int = 2, feat_dim: int = 0, edge_dim: int = 0, hidden_dim: int = 64, \n",
    "#                  dropout: float = 0.1, norm_coors: bool = True, norm_coors_scale_init: float = 1.0, \n",
    "#                  cutoff_distance: float = math.inf, num_layers: int = 1, use_norm: str = None):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.cutoff_distance = cutoff_distance\n",
    "        \n",
    "#         # Create a ModuleList to hold multiple EGNN layers\n",
    "#         self.coordinate_layers = nn.ModuleList([\n",
    "#             Coordinate_EGNN(\n",
    "#                 glob_dim=glob_dim, \n",
    "#                 feat_dim=feat_dim, \n",
    "#                 edge_dim=edge_dim, \n",
    "#                 hidden_dim=hidden_dim, \n",
    "#                 dropout=dropout, \n",
    "#                 norm_coors=norm_coors, \n",
    "#                 norm_coors_scale_init=norm_coors_scale_init, \n",
    "#                 cutoff_distance=cutoff_distance,\n",
    "#                 use_norm=use_norm\n",
    "#             )\n",
    "#             for _ in range(num_layers)\n",
    "#         ])\n",
    "\n",
    "#         self.volume_layers = nn.Sequential(\n",
    "#             Dense(\n",
    "#                 in_features=glob_dim,\n",
    "#                 out_features=hidden_dim,\n",
    "#                 activation='silu'\n",
    "#             ),\n",
    "#             *[ResidualLayer(hidden_dim, 2, activation='silu', name=None)\n",
    "#             for _ in range(num_layers)],\n",
    "#             Dense(\n",
    "#                 in_features=hidden_dim,\n",
    "#                 out_features=1,\n",
    "#                 activation=None\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, t, coors_vol, shape, feats=None, edges=None, mask=None):\n",
    "#         \"\"\"\n",
    "#         Apply multiple EGNN layers sequentially with a single graph construction\n",
    "        \n",
    "#         Args:\n",
    "#             globs: global attributes (batch_size, D')\n",
    "#             coors: flattened coordinate attributes (total_size, d)\n",
    "#             shape: tuple of (batch_size, n_particles, dim) to reshape coordinates\n",
    "#             feats: node features (optional)\n",
    "#             edges: edge features (optional)\n",
    "#             mask: attention mask (optional)\n",
    "#         \"\"\"\n",
    "#         # Extract shape information\n",
    "#         b, n, d = shape\n",
    "        \n",
    "#         coors = coors_vol[:, :-1]\n",
    "#         vol = coors_vol[:, -1:]\n",
    "#         globs = torch.cat([t, vol], dim = -1)\n",
    "\n",
    "#         # Calculate volume\n",
    "#         vol = self.volume_layers(globs)\n",
    "\n",
    "#         # Calculate coordinates\n",
    "#         # Reshape flattened coordinates to (b, n, d) for graph building\n",
    "#         coors = coors.reshape(b, n, d)\n",
    "\n",
    "#         coors_residual = coors\n",
    "        \n",
    "#         # Apply each layer sequentially using the same graph structure\n",
    "#         for layer in self.coordinate_layers:\n",
    "#             # Build graph structure once using the standalone function\n",
    "#             graph_dict = build_graph(coors, self.cutoff_distance, mask)\n",
    "#             coors = layer(graph_dict, globs, coors, feats, edges)\n",
    "        \n",
    "#         coors -= coors_residual\n",
    "\n",
    "#         # Flatten output coordinates back to the input format        \n",
    "#         coors_vol = torch.cat([coors.flatten(start_dim=1), vol], dim = -1)\n",
    "\n",
    "#         return coors_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b861137c-8d5e-412b-a209-e87dd977883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch.nn.init as init\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ee85dc-25a2-4390-9889-7241cb8f7d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1024.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 20 09:42:28 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     Off |   00000000:03:00.0 Off |                    0 |\n",
      "|  0%   44C    P0             80W /  300W |   45503MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3358      C   /usr/local/anaconda3-2024/bin/python        44002MiB |\n",
      "|    0   N/A  N/A      9533      C   /usr/local/anaconda3-2024/bin/python          774MiB |\n",
      "|    0   N/A  N/A     10989      C   /usr/local/anaconda3-2024/bin/python          708MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5553f87-b552-49d7-b142-99ca3548befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time_residual(nn.Module):\n",
    "    def __init__(self, num_hidden_layers=2, num_neurons_per_layer=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input layer: 1D input (time)\n",
    "        self.input_layer = nn.Linear(1, num_neurons_per_layer)\n",
    "\n",
    "        # Hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(num_neurons_per_layer, num_neurons_per_layer) \n",
    "            for _ in range(num_hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layer: 1D output (time residual)\n",
    "        self.output_layer = nn.Linear(num_neurons_per_layer, 1)\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        # Initialize weights using Xavier initialization\n",
    "        nn.init.xavier_normal_(self.input_layer.weight.data)\n",
    "        nn.init.zeros_(self.input_layer.bias.data)\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            nn.init.xavier_normal_(layer.weight.data)\n",
    "            nn.init.zeros_(layer.bias.data)\n",
    "            \n",
    "        nn.init.xavier_normal_(self.output_layer.weight.data)\n",
    "        nn.init.zeros_(self.output_layer.bias.data)\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            t (torch.Tensor): Time input of shape [batch_size, 1]\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Time residual output c_t of shape [batch_size, 1]\n",
    "        \"\"\"\n",
    "        # Pass through network with residual connections\n",
    "        outputs = self.activation(self.input_layer(t))\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            layer_output = self.activation(layer(outputs))\n",
    "            outputs = layer_output + outputs  # Residual connection\n",
    "        \n",
    "        # Final output layer\n",
    "        c_t = self.output_layer(outputs)\n",
    "        \n",
    "        return c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e727c218-5088-4ee0-ad4c-6baf491faf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lennard_jones_energy_full(x, n_particles, n_dims, box_length=2*torch.pi, eps=1.0, rm=1.0, r_switch=0.95, r_cutoff=2.5, remove_diagonal=True):\n",
    "    \"\"\"\n",
    "    Compute Lennard-Jones energy using linear approximation for r < r_cut.\n",
    "    Args:\n",
    "        x: Tensor of shape (B, N * D), flattened particle coordinates\n",
    "        n_particles: Number of particles N\n",
    "        n_dims: Number of spatial dimensions D\n",
    "        box_length: Periodic box size\n",
    "        eps, rm: LJ parameters\n",
    "        r_cut: linear cutoff distance\n",
    "        remove_diagonal: whether to exclude self-interactions\n",
    "        \n",
    "    Returns:\n",
    "        lj_energy: Tensor of shape (B, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Reshape x to (B, N, D)\n",
    "    x = x.view(-1, n_particles, n_dims)\n",
    "\n",
    "    # 2. Apply PBC to compute pairwise displacements: shape (B, N, N, D)\n",
    "    delta = x.unsqueeze(2) - x.unsqueeze(1)  # [B, N, N, D]\n",
    "    delta = delta - box_length * torch.round(delta / box_length)\n",
    "\n",
    "    # 3. Optionally remove diagonal entries\n",
    "    if remove_diagonal:\n",
    "        B, N, _, D = delta.shape\n",
    "        mask = ~torch.eye(N, dtype=torch.bool, device=x.device)  # [N, N]\n",
    "        mask = mask.unsqueeze(0).expand(B, N, N)                 # [B, N, N]\n",
    "        delta = delta[mask].view(B, N, N - 1, D)\n",
    "\n",
    "    # 4. Compute distances r = ||delta||: shape (B, N, N-1)\n",
    "    r = delta.pow(2).sum(dim=-1).sqrt()  # [B, N, N-1]\n",
    "\n",
    "    # 5. Compute linear approximation: V = a * r + b where r < r_cut\n",
    "    a = -10.0\n",
    "    lj_at_cut = 4.0 * eps * ((rm / r_switch)**12 - (rm / r_switch)**6)\n",
    "    b = lj_at_cut - a * r_switch\n",
    "    V = a * r + b\n",
    "\n",
    "    # 6. Apply full LJ where r >= r_cut\n",
    "    mask = (r >= r_switch)\n",
    "    if mask.any():\n",
    "        r_big = r[mask]\n",
    "        V[mask] = 4.0 * eps * ((rm / r_big)**12 - (rm / r_big)**6)\n",
    "    \n",
    "    V[r > r_cutoff] = 0.0\n",
    "\n",
    "    # 7. Sum over all pairwise terms, divide by 2 to avoid double counting\n",
    "    lj_energy = V.sum(dim=(-2, -1)) / 2  # shape (B,)\n",
    "    \n",
    "    return lj_energy[:, None]  # shape (B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef112c0-dcef-46dd-9bb2-6d896a79a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_distance(samples,Velocity,f_t):\n",
    "    # Samples is a tensor of shape (B, N*D）\n",
    "    # Velocity_field is a tensor of shape (B, N*D)\n",
    "    # Internal_energy_ is a tensor of shape (B,1)\n",
    "    # Expected result is a tensor of shape (B,1)\n",
    "    \n",
    "    gradient = torch.autograd.grad(f_t, samples, grad_outputs=torch.ones_like(f_t), create_graph=True)[0]\n",
    "    # Detect when gradient exists Nan, output samples and inter_energy\n",
    "\n",
    "    if torch.isnan(gradient).any():\n",
    "        nan_mask = torch.isnan(gradient).any(dim=1)\n",
    "        print(\"NaN detected in gradient!\")\n",
    "        print(\"Problematic samples:\\n\", samples[nan_mask])\n",
    "        print(\"Corresponding internal energy:\\n\", f_t[nan_mask])\n",
    "        raise ValueError(\"NaN detected in gradient computation.\")\n",
    "\n",
    "    # Compute the distance\n",
    "    result = torch.sum(gradient * Velocity,dim = 1)\n",
    "    \n",
    "    assert not torch.isnan(result).any(), \"Result is NaN\"\n",
    "    result = result.unsqueeze(dim = 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c8a681-6a2d-49d0-975c-83d43d0e86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_divergence(Velocity, t, x, n_particles, n_dimension, n_pde_points):\n",
    "    \"\"\"\n",
    "    model: the neural network representing the vector field\n",
    "    t: torch tensor of shape [B, 1]\n",
    "    x: torch tensor of shape [B, D]\n",
    "    \"\"\"\n",
    "    x.requires_grad_(True)\n",
    "    v = Velocity(t, x, (n_pde_points, n_particles, n_dimension))  # [B, D]\n",
    "    \n",
    "    divergence = torch.zeros(x.shape[0], device=x.device)\n",
    "    for i in range(v.shape[1]):\n",
    "        grad_v_i = torch.autograd.grad(\n",
    "            outputs=v[:, i],\n",
    "            inputs=x,\n",
    "            grad_outputs=torch.ones_like(v[:, i]),\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0][:, i]  # 只取 ∂v_i/∂x_i\n",
    "        divergence += grad_v_i\n",
    "\n",
    "    return divergence.view(-1,1)  # shape [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b4c868-bfc1-4305-92ac-9dce6c5e1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_formula(x, t_value, Velocity_model, Normalizing_model, n_particles, n_dimension, n_pde_points):\n",
    "    '''\n",
    "    t_value: torch tensor of shape [B, 1]\n",
    "    x: torch tensor of shape [B, N*D]\n",
    "    '''\n",
    "    # First term is energy\n",
    "    U = lennard_jones_energy_full(x, n_particles, n_dimension)\n",
    "    f_t = t_value * U\n",
    "    # check if U is NaN\n",
    "    assert torch.isnan(f_t).sum() == 0, \"Energy is NaN\"\n",
    "\n",
    "    shape = (n_pde_points, n_particles, n_dimension)\n",
    "    velocity_field = Velocity_model(t_value, x, shape)\n",
    "    assert torch.isnan(velocity_field).sum() == 0, \"Velocity field is NaN\"\n",
    "    \n",
    "    term2 = vector_distance(x, velocity_field, f_t)\n",
    "    assert torch.isnan(term2).sum() == 0, \"Term2 is NaN\"\n",
    "        \n",
    "    trace_average = compute_divergence(Velocity_model, t_value, x, n_particles, n_dimension, n_pde_points)\n",
    "    assert torch.isnan(trace_average).sum() == 0, \"Trace average is NaN\"\n",
    "\n",
    "    C_t = Normalizing_model(t_value)\n",
    "    assert torch.isnan(C_t).sum() == 0, \"C_t is NaN\"\n",
    "\n",
    "    return torch.abs(U + term2 - trace_average +C_t) + (U + term2 - trace_average +C_t)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afdd8316-0493-4bb1-b130-40ca41e6dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for 2D PINN with time range [0.1, 1] and vector output correction\n",
    "def compute_loss(Velocity, Time_residual, n_particles, n_dimension, device=\"cuda\", bound = 2*torch.pi):\n",
    "    # Sample collocation points for PDE residual\n",
    "    n_pde_points = 36  # Number of points inside domain\n",
    "    samples = torch.rand(n_pde_points, n_particles*n_dimension, device=device,requires_grad=True) * bound - bound/2  # Range [-10, 10]\n",
    "    t_value = 1.0 - torch.rand(n_pde_points, 1, device=device)\n",
    "    pde_loss_t = pde_formula(samples, t_value, Velocity, Time_residual, n_particles, n_dimension, n_pde_points)\n",
    "    pde_loss = torch.mean(pde_loss_t)\n",
    "\n",
    "   \n",
    "    # Initial condition points at t=0.1 (smallest valid t)\n",
    "    n_ic_points = 18\n",
    "    shape = (n_ic_points, n_particles, n_dimension)\n",
    "    samples_prior_ic = torch.rand(n_ic_points, n_particles*n_dimension, device=device)* bound - bound/2    # Range [-10, 10]\n",
    "    t_ic = torch.zeros(n_ic_points, 1, device=device)      \n",
    "    u_ic_pred = Velocity(t_ic, samples_prior_ic, shape)\n",
    "    u_ic_true = 1\n",
    "    ic_loss = torch.sum((u_ic_pred - u_ic_true)**2,dim = 1)\n",
    "    ic_loss = torch.mean(ic_loss)\n",
    "    \n",
    "    # Boundary conditions\n",
    "    n_bc_points = 18\n",
    "    shape = (n_bc_points, n_particles, n_dimension)\n",
    "    # Left boundary (x = -10)\n",
    "    samples_prior_left = torch.rand(n_bc_points, n_particles*n_dimension, device=device)* bound - bound/2 \n",
    "    samples_prior_left[:, 0] = -torch.pi   # Range [-10, 10]\n",
    "    t_bc_left = torch.rand(n_bc_points, 1, device=device)  \n",
    "    u_bc_left_pred = Velocity(t_bc_left, samples_prior_left, shape)\n",
    "    u_bc_left_true = torch.zeros_like(u_bc_left_pred, device=device)\n",
    "    bc_loss_left = torch.sum((u_bc_left_pred - u_bc_left_true)**2,dim = 1)\n",
    "    bc_loss_left = torch.mean(bc_loss_left)\n",
    "    \n",
    "    # Right boundary (x = 10)\n",
    "    samples_prior_right = torch.rand(n_bc_points, n_particles*n_dimension, device=device)* bound - bound/2 \n",
    "    samples_prior_right[:, 0] = torch.pi\n",
    "    t_bc_right = torch.rand(n_bc_points, 1, device=device)   \n",
    "    u_bc_right_pred = Velocity(t_bc_right, samples_prior_right, shape)\n",
    "    u_bc_right_true = torch.zeros_like(u_bc_right_pred, device=device)\n",
    "    bc_loss_right = torch.sum((u_bc_right_pred - u_bc_right_true)**2,dim = 1)\n",
    "    bc_loss_right = torch.mean(bc_loss_right)\n",
    "    \n",
    "    # Bottom boundary (y = -10)\n",
    "    samples_prior_bottom = torch.rand(n_bc_points, n_particles*n_dimension, device=device)* bound - bound/2\n",
    "    samples_prior_bottom[:, 1] = -torch.pi  \n",
    "    t_bc_bottom = torch.rand(n_bc_points, 1, device=device) \n",
    "    u_bc_bottom_pred = Velocity(t_bc_bottom, samples_prior_bottom, shape)\n",
    "    u_bc_bottom_true = torch.zeros_like(u_bc_bottom_pred, device=device)\n",
    "    bc_loss_bottom = torch.sum((u_bc_bottom_pred - u_bc_bottom_true)**2,dim = 1)\n",
    "    bc_loss_bottom = torch.mean(bc_loss_bottom)\n",
    "    \n",
    "    # Top boundary (y = 10)\n",
    "    samples_prior_top = torch.rand(n_bc_points, n_particles*n_dimension, device=device)* bound - bound/2\n",
    "    samples_prior_top[:, 1] = torch.pi\n",
    "    t_bc_top = torch.rand(n_bc_points, 1, device=device) \n",
    "    u_bc_top_pred = Velocity(t_bc_top, samples_prior_top, shape)\n",
    "    u_bc_top_true = torch.zeros_like(u_bc_top_pred, device=device)\n",
    "    bc_loss_top = torch.sum((u_bc_top_pred - u_bc_top_true)**2,dim = 1)\n",
    "    bc_loss_top = torch.mean(bc_loss_top)\n",
    "\n",
    "    # Total boundary loss\n",
    "    bc_loss = bc_loss_left + bc_loss_right + bc_loss_bottom + bc_loss_top\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = pde_loss + ic_loss + bc_loss \n",
    "    \n",
    "    return total_loss, pde_loss, ic_loss, bc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f590c09-ab39-4bef-89bf-78390472931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(n_particles, n_dimension, Velocity, Time_residual, optimizer,scheduler, device=\"cuda\",n_epochs=10000, print_every=1000):\n",
    "    start_time = time.time()\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss,pde_loss,ic_loss,bc_loss = compute_loss(Velocity, Time_residual, n_particles, n_dimension,device)\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        \n",
    "        loss_history.append(total_loss.item())\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Epoch {epoch}/{n_epochs} - Time: {elapsed:.2f}s - \"\n",
    "                  f\"Loss: {total_loss.item():.6f}, PDE: {pde_loss.item():.6f}, \"\n",
    "                  f\"IC: {ic_loss.item():.6f}, BC: {bc_loss.item():.6f}\")\n",
    "    \n",
    "    print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "    return Velocity, Time_residual, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1a190d-4d9f-4cf4-9aef-996b595f316c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m      8\u001b[0m n_neurons_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m Velocity \u001b[38;5;241m=\u001b[39m PINN2D(\n\u001b[1;32m     12\u001b[0m     glob_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,         \u001b[38;5;66;03m# 每个边的全局特征维度（例如温度、系统能量等）\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     feat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,         \u001b[38;5;66;03m# 每个粒子的特征维度\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     edge_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,         \u001b[38;5;66;03m# 每对粒子的边特征维度（可选）\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,      \u001b[38;5;66;03m# 每层的隐藏层维度\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     norm_coors_scale_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,  \u001b[38;5;66;03m# 坐标归一化初始缩放因子\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     cutoff_distance\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpi,  \u001b[38;5;66;03m# 截断距离\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m        \u001b[38;5;66;03m# 使用3层Coordinate_EGNN网络\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m Time \u001b[38;5;241m=\u001b[39m Time_residual(n_layers_T, n_neurons_T)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mlist\u001b[39m(Velocity\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(Time\u001b[38;5;241m.\u001b[39mparameters()), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 779 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2024/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1160\u001b[0m         device,\n\u001b[1;32m   1161\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1162\u001b[0m         non_blocking,\n\u001b[1;32m   1163\u001b[0m     )\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "n_particles = 3\n",
    "n_dimension = 2\n",
    "\n",
    "n_layers_V = 2\n",
    "n_neurons_V = 128\n",
    "\n",
    "n_layers_T = 1\n",
    "n_neurons_T = 128\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "Velocity = PINN2D(\n",
    "    glob_dim=1,         # 每个边的全局特征维度（例如温度、系统能量等）\n",
    "    feat_dim=0,         # 每个粒子的特征维度\n",
    "    edge_dim=0,         # 每对粒子的边特征维度（可选）\n",
    "    hidden_dim=128,      # 每层的隐藏层维度\n",
    "    norm_coors_scale_init=1.0,  # 坐标归一化初始缩放因子\n",
    "    cutoff_distance=torch.pi,  # 截断距离\n",
    "    num_layers=1        # 使用3层Coordinate_EGNN网络\n",
    ").to(device)\n",
    "Time = Time_residual(n_layers_T, n_neurons_T).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(Velocity.parameters()) + list(Time.parameters()), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=1000, gamma=0.5)\n",
    "\n",
    "# from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "# scheduler = CyclicLR(\n",
    "#     optimizer,\n",
    "#     base_lr=1e-5,              # 最低 lr\n",
    "#     max_lr=1e-2,               # 初始峰值\n",
    "#     step_size_up=1000,         # 上升到峰值需要 2000 步\n",
    "#     step_size_down=1000,       # 再下降回最低也 2000 步\n",
    "#     mode='triangular',        # 每个周期峰值自动乘 1/2\n",
    "#     cycle_momentum=False\n",
    "# )\n",
    "\n",
    "\n",
    "Velocity, Time, loss_history = train(\n",
    "    n_particles=n_particles,\n",
    "    n_dimension=n_dimension,\n",
    "    Velocity=Velocity,\n",
    "    Time_residual=Time,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    n_epochs=10000,\n",
    "    print_every=200\n",
    ")\n",
    "\n",
    "torch.save(Velocity.state_dict(), \"Exp1_velocity_model.pth\")\n",
    "torch.save(Time.state_dict(), \"Exp1_time_model.pth\")\n",
    "\n",
    "# Plot loss history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss History')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0f491c-12ad-468f-90cd-58c07d133653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def envelope_function(d_scaled, p):\n",
    "    a = -(p + 1) * (p + 2) / 2\n",
    "    b = p * (p + 2)\n",
    "    c = -p * (p + 1) / 2\n",
    "\n",
    "    env_val = (\n",
    "        1\n",
    "        + a * d_scaled ** p\n",
    "        + b * d_scaled ** (p + 1)\n",
    "        + c * d_scaled ** (p + 2)\n",
    "    )\n",
    "    env_val[d_scaled >= 1] = 0.0\n",
    "    return env_val\n",
    "\n",
    "# 参数设置\n",
    "p = 5\n",
    "x = np.linspace(0, 1.5, 300)\n",
    "y = envelope_function(x, p)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, label=f'Envelope p={p}')\n",
    "plt.xlabel(\"d_scaled\")\n",
    "plt.ylabel(\"Envelope value\")\n",
    "plt.title(\"Smooth Envelope Function\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9589f65-7be5-4c08-95de-989518df94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "Velocity = PINN2D(\n",
    "    glob_dim=1,         # 每个边的全局特征维度（例如温度、系统能量等）\n",
    "    feat_dim=0,         # 每个粒子的特征维度\n",
    "    edge_dim=0,         # 每对粒子的边特征维度（可选）\n",
    "    hidden_dim=128,      # 每层的隐藏层维度\n",
    "    norm_coors_scale_init=1.0,  # 坐标归一化初始缩放因子\n",
    "    cutoff_distance=2*torch.pi,  # 截断距离\n",
    "    num_layers=1        # 使用3层Coordinate_EGNN网络\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e231343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1802e-04,  1.6451e-05, -1.1802e-04, -1.6451e-05,  0.0000e+00,\n",
       "          0.0000e+00],\n",
       "        [-1.3113e-05,  6.3181e-05,  0.0000e+00,  0.0000e+00,  1.3113e-05,\n",
       "         -6.3181e-05]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pde_points = 2  # Number of points inside domain\n",
    "bound = torch.pi * 2\n",
    "n_particles = 3\n",
    "n_dimension = 2\n",
    "samples = torch.rand(n_pde_points, n_particles*n_dimension, device=device,requires_grad=True) * bound - bound/2  # Range [-10, 10]\n",
    "t_value = torch.ones(n_pde_points, 1, device=device)\n",
    "shape = (n_pde_points, n_particles, n_dimension)\n",
    "# 计算速度场\n",
    "velocity_field = Velocity(t_value, samples, shape)\n",
    "velocity_field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d4bef",
   "metadata": {},
   "source": [
    "# Translation equivariance\n",
    "\n",
    "$y+g = \\Phi(x+g)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e970123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: tensor([[[ 2.2567,  3.0465],\n",
      "         [ 1.5930, -0.8757]],\n",
      "\n",
      "        [[ 0.4660, -2.1148],\n",
      "         [-1.7998, -1.6567]]], grad_fn=<ViewBackward0>)\n",
      "translation: tensor([[1., 1.]])\n",
      "after: tensor([[[-3.0265, -2.2367],\n",
      "         [ 2.5930,  0.1243]],\n",
      "\n",
      "        [[ 1.4660, -1.1148],\n",
      "         [-0.7998, -0.6567]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_pde_points = 2  # Number of points inside domain\n",
    "bound = torch.pi*2 \n",
    "n_particles = 2\n",
    "n_dimension = 2\n",
    "\n",
    "samples = torch.rand(n_pde_points, n_particles*n_dimension, device=device,requires_grad=True) * bound - bound/2\n",
    "t_value = torch.ones(n_pde_points, 1, device=device)\n",
    "shape = (n_pde_points, n_particles, n_dimension)\n",
    "trans_vec = (torch.ones(1, n_dimension, device=device) * 2 - 1) * 1\n",
    "samples = samples.reshape(n_pde_points, n_particles, n_dimension)\n",
    "samples_trans = (samples + trans_vec) - bound * torch.round((samples + trans_vec) / (bound))\n",
    "print(\"original:\", samples) \n",
    "print(\"translation:\", trans_vec)\n",
    "print(\"after:\", samples_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e0cf069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_original: tensor([[ 2.2567,  3.0465,  1.5930, -0.8757],\n",
      "        [ 0.4660, -2.1148, -1.7998, -1.6567]], grad_fn=<ViewBackward0>)\n",
      "samples_after tensor([[-3.0265, -2.2367,  2.5930,  0.1243],\n",
      "        [ 1.4660, -1.1148, -0.7998, -0.6567]], grad_fn=<ViewBackward0>)\n",
      "velocity_original: tensor([[ 0.0003, -0.0010, -0.0003,  0.0010],\n",
      "        [ 0.0195, -0.0039, -0.0195,  0.0039]], grad_fn=<ViewBackward0>)\n",
      "velocity_after: tensor([[ 0.0003, -0.0010, -0.0003,  0.0010],\n",
      "        [ 0.0195, -0.0039, -0.0195,  0.0039]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "velocity_original = Velocity(t_value, samples.reshape(n_pde_points, -1), shape)\n",
    "velocity_after = Velocity(t_value, samples_trans.reshape(n_pde_points, -1), shape)\n",
    "\n",
    "print(\"samples_original:\", samples.reshape(n_pde_points, -1))\n",
    "print(\"samples_after\", samples_trans.reshape(n_pde_points, -1))\n",
    "print(\"velocity_original:\", velocity_original)\n",
    "print(\"velocity_after:\", velocity_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
